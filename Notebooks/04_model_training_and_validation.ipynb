{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "44987ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "7da7e898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows,cols: (11895, 16)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/cleaned_book_ratings_plus.csv\")\n",
    "df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
    "df[\"isbn\"] = df[\"isbn\"].astype(str)\n",
    "books=df.drop_duplicates(subset='isbn')[['isbn','book_rating','title','author','year','publisher','img_url','num_of_rating','avg_book_rate','weighted_score']]\n",
    "users=df.drop_duplicates(subset='user_id')[['user_id','user_age','location','fav_author','fav_publisher']]\n",
    "\n",
    "print(\"rows,cols:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "a62f2a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11895 entries, 0 to 11894\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Unnamed: 0      11895 non-null  int64  \n",
      " 1   user_id         11895 non-null  object \n",
      " 2   isbn            11895 non-null  object \n",
      " 3   book_rating     11895 non-null  int64  \n",
      " 4   location        11895 non-null  object \n",
      " 5   user_age        11895 non-null  float64\n",
      " 6   title           11895 non-null  object \n",
      " 7   author          11895 non-null  object \n",
      " 8   year            11895 non-null  float64\n",
      " 9   publisher       11895 non-null  object \n",
      " 10  img_url         11895 non-null  object \n",
      " 11  num_of_rating   11895 non-null  int64  \n",
      " 12  fav_author      11895 non-null  object \n",
      " 13  fav_publisher   11895 non-null  object \n",
      " 14  avg_book_rate   11895 non-null  float64\n",
      " 15  weighted_score  11895 non-null  float64\n",
      "dtypes: float64(4), int64(3), object(9)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eff5ce4",
   "metadata": {},
   "source": [
    "# Popularity filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "72cdf55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_rated_books = df.sort_values(\"weighted_score\", ascending=False)\n",
    "top_rated_books=top_rated_books.drop_duplicates(subset=['isbn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "9b0a48c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_books(n):\n",
    "    \"\"\"\n",
    "    Returns the top n books from top_rated_books DataFrame\n",
    "    with columns: title, num_of_rating, avg_book_rate, weighted_score.\n",
    "    \"\"\"\n",
    "    return top_rated_books[\n",
    "        [\"title\", \"num_of_rating\", \"avg_book_rate\", \"weighted_score\"]\n",
    "    ].head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "c980dbb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>num_of_rating</th>\n",
       "      <th>avg_book_rate</th>\n",
       "      <th>weighted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8130</th>\n",
       "      <td>Harry Potter and the Goblet of Fire (Book 4)</td>\n",
       "      <td>72</td>\n",
       "      <td>9.512195</td>\n",
       "      <td>9.302108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10187</th>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban (Book 3)</td>\n",
       "      <td>70</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>9.146198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>The Return of the King (The Lord of the Rings,...</td>\n",
       "      <td>19</td>\n",
       "      <td>9.789474</td>\n",
       "      <td>9.118784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>Where the Red Fern Grows</td>\n",
       "      <td>17</td>\n",
       "      <td>9.588235</td>\n",
       "      <td>8.960036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4348</th>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban (Book 3)</td>\n",
       "      <td>70</td>\n",
       "      <td>9.083333</td>\n",
       "      <td>8.935355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix (Boo...</td>\n",
       "      <td>63</td>\n",
       "      <td>9.079365</td>\n",
       "      <td>8.918435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>57</td>\n",
       "      <td>9.087719</td>\n",
       "      <td>8.911444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384</th>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n",
       "      <td>55</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>8.908840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>The Two Towers (The Lord of the Rings, Part 2)</td>\n",
       "      <td>18</td>\n",
       "      <td>9.444444</td>\n",
       "      <td>8.896809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7765</th>\n",
       "      <td>Lamb : The Gospel According to Biff, Christ's ...</td>\n",
       "      <td>16</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>8.889693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  num_of_rating  \\\n",
       "8130        Harry Potter and the Goblet of Fire (Book 4)             72   \n",
       "10187  Harry Potter and the Prisoner of Azkaban (Book 3)             70   \n",
       "1219   The Return of the King (The Lord of the Rings,...             19   \n",
       "1658                            Where the Red Fern Grows             17   \n",
       "4348   Harry Potter and the Prisoner of Azkaban (Book 3)             70   \n",
       "789    Harry Potter and the Order of the Phoenix (Boo...             63   \n",
       "2345                               To Kill a Mockingbird             57   \n",
       "4384   Harry Potter and the Sorcerer's Stone (Harry P...             55   \n",
       "34        The Two Towers (The Lord of the Rings, Part 2)             18   \n",
       "7765   Lamb : The Gospel According to Biff, Christ's ...             16   \n",
       "\n",
       "       avg_book_rate  weighted_score  \n",
       "8130        9.512195        9.302108  \n",
       "10187       9.333333        9.146198  \n",
       "1219        9.789474        9.118784  \n",
       "1658        9.588235        8.960036  \n",
       "4348        9.083333        8.935355  \n",
       "789         9.079365        8.918435  \n",
       "2345        9.087719        8.911444  \n",
       "4384        9.090909        8.908840  \n",
       "34          9.444444        8.896809  \n",
       "7765        9.500000        8.889693  "
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n_books(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09ebedd",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3726b250",
   "metadata": {},
   "source": [
    "Split ratings into training set and test set so that:\n",
    "\n",
    "- Each user has at least num_of_rates_in_test ratings placed in the test set.\n",
    "\n",
    "- The rest of the ratings stay in the train set.\n",
    "\n",
    "This ensures every user appears in both train and test, which is crucial for evaluating recommendation systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "58b7c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_one_in_test(df,num_of_rates_in_test=1):\n",
    "    grouped=df.groupby('user_id')\n",
    "    train_list=[]\n",
    "    test_list=[]\n",
    "    for uid,g in grouped:\n",
    "        if len(g) <= num_of_rates_in_test:\n",
    "            test_list.append(g.index.values)\n",
    "            continue\n",
    "\n",
    "        test_idx = g.sample(n=num_of_rates_in_test,random_state=42).index\n",
    "        train_idx = g.index.difference(test_idx)\n",
    "        test_list.extend(list(test_idx))\n",
    "        train_list.extend(list(train_idx))\n",
    "\n",
    "    train_df=df.loc[train_list]\n",
    "    test_df=df.loc[test_list]\n",
    "    return train_df.reset_index(drop=True), test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "b76d47c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (11293, 16) test: (602, 16)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df=train_test_split_one_in_test(df)\n",
    "print(\"train:\", train_df.shape, \"test:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1f6ad8",
   "metadata": {},
   "source": [
    "# Item Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "328f1e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix = train_df.pivot_table(\n",
    "    index=\"user_id\", columns=\"isbn\", values=\"book_rating\", fill_value=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "680fd300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>isbn</th>\n",
       "      <th>002542730X</th>\n",
       "      <th>0060096195</th>\n",
       "      <th>006016848X</th>\n",
       "      <th>0060199652</th>\n",
       "      <th>0060391626</th>\n",
       "      <th>0060392452</th>\n",
       "      <th>0060502258</th>\n",
       "      <th>0060915544</th>\n",
       "      <th>0060916508</th>\n",
       "      <th>0060920084</th>\n",
       "      <th>...</th>\n",
       "      <th>1558743669</th>\n",
       "      <th>1558744150</th>\n",
       "      <th>1558745157</th>\n",
       "      <th>1565122968</th>\n",
       "      <th>1573225517</th>\n",
       "      <th>1573225789</th>\n",
       "      <th>1573229326</th>\n",
       "      <th>1573229571</th>\n",
       "      <th>1592400876</th>\n",
       "      <th>1878424319</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100459</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100644</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100846</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100906</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101305</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98263</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98391</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98758</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98787</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98904</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>602 rows × 629 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "isbn     002542730X  0060096195  006016848X  0060199652  0060391626  \\\n",
       "user_id                                                               \n",
       "100459          0.0         0.0         0.0         8.0         0.0   \n",
       "100644          0.0         0.0         0.0         0.0         0.0   \n",
       "100846          0.0         0.0         0.0         0.0         0.0   \n",
       "100906          0.0         0.0         0.0         0.0         0.0   \n",
       "101305          0.0         0.0         0.0         0.0         0.0   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "98263           0.0         0.0         0.0         0.0         0.0   \n",
       "98391           0.0         0.0         0.0         0.0         0.0   \n",
       "98758           0.0         0.0         0.0         0.0         0.0   \n",
       "98787           0.0         0.0         0.0         0.0         0.0   \n",
       "98904           0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "isbn     0060392452  0060502258  0060915544  0060916508  0060920084  ...  \\\n",
       "user_id                                                              ...   \n",
       "100459          9.0         0.0         0.0         0.0         0.0  ...   \n",
       "100644          0.0         0.0         0.0         0.0         0.0  ...   \n",
       "100846          0.0         0.0         0.0         0.0         0.0  ...   \n",
       "100906          0.0         0.0         0.0         0.0         0.0  ...   \n",
       "101305          0.0         0.0         0.0         0.0         0.0  ...   \n",
       "...             ...         ...         ...         ...         ...  ...   \n",
       "98263           0.0         0.0         0.0         0.0         0.0  ...   \n",
       "98391           0.0         0.0         0.0         0.0         0.0  ...   \n",
       "98758           0.0         0.0         0.0         0.0         0.0  ...   \n",
       "98787           0.0         0.0         0.0         0.0         0.0  ...   \n",
       "98904           0.0        10.0         0.0         0.0         0.0  ...   \n",
       "\n",
       "isbn     1558743669  1558744150  1558745157  1565122968  1573225517  \\\n",
       "user_id                                                               \n",
       "100459          0.0         0.0         0.0         0.0         0.0   \n",
       "100644          0.0         0.0         0.0         0.0         0.0   \n",
       "100846          0.0         0.0         0.0         0.0         0.0   \n",
       "100906          0.0         0.0         0.0         0.0         0.0   \n",
       "101305          0.0         0.0         0.0         0.0         0.0   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "98263           0.0         0.0         0.0         0.0         0.0   \n",
       "98391           0.0         0.0         0.0         0.0         0.0   \n",
       "98758           0.0         0.0         0.0         0.0         0.0   \n",
       "98787           0.0         0.0         0.0         0.0         0.0   \n",
       "98904           0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "isbn     1573225789  1573229326  1573229571  1592400876  1878424319  \n",
       "user_id                                                              \n",
       "100459          0.0         0.0         0.0         0.0         0.0  \n",
       "100644          0.0         0.0         0.0         0.0         0.0  \n",
       "100846          0.0         0.0         0.0         0.0         0.0  \n",
       "100906          0.0         0.0         0.0         0.0         0.0  \n",
       "101305          0.0         0.0         0.0         0.0         0.0  \n",
       "...             ...         ...         ...         ...         ...  \n",
       "98263           0.0         0.0         0.0         0.0         0.0  \n",
       "98391           0.0         0.0         0.0         0.0         0.0  \n",
       "98758           0.0         0.0         0.0         0.0         0.0  \n",
       "98787           0.0         0.0         0.0         0.0         0.0  \n",
       "98904           0.0         0.0         0.0         0.0         0.0  \n",
       "\n",
       "[602 rows x 629 columns]"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6a1b5a",
   "metadata": {},
   "source": [
    "## based on Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "e326c32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books(book_isbn,min_ratings):\n",
    "    book_ratings = user_item_matrix[book_isbn]\n",
    "    similar_books = user_item_matrix.corrwith(book_ratings)\n",
    "    corr_book = pd.DataFrame(similar_books, columns=[\"pearsonR\"])\n",
    "    corr_book.dropna(inplace=True)\n",
    "    \n",
    "    meta = books.set_index(\"isbn\")[[\"num_of_rating\",'title']]\n",
    "    corr_book = corr_book.join(meta)\n",
    "\n",
    "    top_books=corr_book[corr_book['num_of_rating']>=min_ratings]\n",
    "    top_books = top_books.sort_values(\"pearsonR\", ascending=False).head(10)\n",
    "\n",
    "    return top_books\n",
    "# recommended_books = recommend_books('059035342X', 100)\n",
    "# display(recommended_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a517dcf",
   "metadata": {},
   "source": [
    "## based on Cosine similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "66952e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sparse_user_item = csr_matrix(user_item_matrix.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "4e8f80d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 11293 stored elements and shape (602, 629)>"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_user_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "9cea91a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item-user matrix (transpose so rows = items, cols = users)\n",
    "item_user_matrix = sparse_user_item.T  # shape: n_items × n_users\n",
    "\n",
    "# cosine similarity between items\n",
    "item_sim_matrix = cosine_similarity(item_user_matrix, dense_output=False)\n",
    "\n",
    "# map ISBNs to column indices\n",
    "isbn_list = user_item_matrix.columns.tolist()\n",
    "isbn_to_idx = {isbn: i for i, isbn in enumerate(isbn_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "7171622e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>similarity</th>\n",
       "      <th>num_of_rating</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0316666343</td>\n",
       "      <td>0.118338</td>\n",
       "      <td>114</td>\n",
       "      <td>The Lovely Bones: A Novel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           isbn  similarity  num_of_rating                      title\n",
       "105  0316666343    0.118338            114  The Lovely Bones: A Novel"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def recommend_books_cosine(book_isbn, min_ratings=50, top_n=10):\n",
    "    if book_isbn not in isbn_to_idx:\n",
    "        return pd.DataFrame()  # return empty DataFrame instead of None\n",
    "\n",
    "    idx = isbn_to_idx[book_isbn]\n",
    "    # similarity scores for this book vs all others\n",
    "    sim_scores = item_sim_matrix[idx].toarray().ravel()\n",
    "\n",
    "    # build DataFrame of scores (use \"similarity\" instead of \"cosine_sim\")\n",
    "    corr_book = pd.DataFrame({\"isbn\": isbn_list, \"similarity\": sim_scores})\n",
    "\n",
    "    # drop self (the book itself will have sim=1)\n",
    "    corr_book = corr_book[corr_book[\"isbn\"] != book_isbn]\n",
    "\n",
    "    # join metadata (safe join)\n",
    "    meta = books.set_index(\"isbn\")[[\"num_of_rating\", \"title\"]]\n",
    "    corr_book = corr_book.set_index(\"isbn\").join(meta, how=\"inner\").reset_index()\n",
    "\n",
    "    # filter and sort\n",
    "    top_books = corr_book[corr_book[\"num_of_rating\"] >= min_ratings]\n",
    "    top_books = top_books.sort_values(\"similarity\", ascending=False).head(top_n)\n",
    "\n",
    "    return top_books\n",
    "\n",
    "\n",
    "# Example\n",
    "recommended_books = recommend_books_cosine(\"059035342X\", min_ratings=100)\n",
    "display(recommended_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a5fd0c",
   "metadata": {},
   "source": [
    "### User Recommendation Based On ItemCF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5114df86",
   "metadata": {},
   "source": [
    "- Compute **cosine similarity** between items (columns of the user–item matrix).  \n",
    "- For a target user:\n",
    "  1. Look at books the user rated highly.  \n",
    "  2. Find similar books (using cosine similarity).  \n",
    "  3. Aggregate across multiple liked books.  \n",
    "  4. Recommend the most similar unseen books.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "5cbc232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books_itemcf_for_user(user_id, train_df, top_n=10):\n",
    "    # 1. Get all books the user rated highly\n",
    "    user_books = train_df[train_df[\"user_id\"] == user_id]\n",
    "    user_books = user_books[user_books[\"book_rating\"] >= 4][\"isbn\"]\n",
    "\n",
    "    recs = pd.DataFrame()\n",
    "    for isbn in user_books:\n",
    "        recs = pd.concat([recs, recommend_books_cosine(isbn, top_n=5)])\n",
    "\n",
    "    # aggregate by similarity score, drop books already seen\n",
    "    recs = recs.groupby(\"isbn\")[\"similarity\"].mean().reset_index()\n",
    "    recs = recs[~recs[\"isbn\"].isin(user_books)]\n",
    "    return recs.sort_values(\"similarity\", ascending=False).head(top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998e720d",
   "metadata": {},
   "source": [
    "# User Based Collaborative Filtering using Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b97d3",
   "metadata": {},
   "source": [
    "- Compute **cosine similarity** between users (rows of the user–item matrix).  \n",
    "- For a target user:\n",
    "  1. Find the most similar users.  \n",
    "  2. Aggregate their ratings (weighted by similarity).  \n",
    "  3. Recommend items the target user hasn’t seen.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "d863ffdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-item matrix (rows = users, cols = items)\n",
    "\n",
    "# cosine similarity between users\n",
    "user_sim_matrix = cosine_similarity(\n",
    "    sparse_user_item, dense_output=False\n",
    ")  # n_users × n_users\n",
    "\n",
    "# mappings for user_id\n",
    "user_list = user_item_matrix.index.tolist()\n",
    "user_to_idx = {uid: i for i, uid in enumerate(user_list)}\n",
    "idx_to_user = {i: uid for uid, i in user_to_idx.items()}\n",
    "\n",
    "isbn_list = user_item_matrix.columns.tolist()\n",
    "isbn_to_idx = {isbn: i for i, isbn in enumerate(isbn_list)}\n",
    "idx_to_isbn = {i: isbn for isbn, i in isbn_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "0d80074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute lookups (outside function, once)\n",
    "isbn_to_title = dict(zip(books[\"isbn\"], books[\"title\"]))\n",
    "isbn_to_num = dict(zip(books[\"isbn\"], books[\"num_of_rating\"]))\n",
    "\n",
    "\n",
    "def recommend_books_userCF(user_id, top_n=10, min_ratings=50):\n",
    "    if user_id not in user_to_idx:\n",
    "        return None\n",
    "\n",
    "    uidx = user_to_idx[user_id]\n",
    "\n",
    "    # similarity scores between this user and all others\n",
    "    sim_scores = user_sim_matrix[uidx].toarray().ravel()\n",
    "\n",
    "    # find top similar users (excluding self)\n",
    "    similar_users = np.argsort(sim_scores)[::-1][1:25]\n",
    "\n",
    "    # collect seen items\n",
    "    seen_items = set(sparse_user_item[uidx].indices)\n",
    "\n",
    "    scores = {}\n",
    "    for sim_u in similar_users:\n",
    "        weight = sim_scores[sim_u]\n",
    "        # get only nonzero entries for this user\n",
    "        sim_user_items = sparse_user_item[sim_u].indices\n",
    "        sim_user_ratings = sparse_user_item[sim_u].data\n",
    "        for item_idx, rating in zip(sim_user_items, sim_user_ratings):\n",
    "            if item_idx not in seen_items:\n",
    "                scores[item_idx] = scores.get(item_idx, 0) + weight * rating\n",
    "\n",
    "    # sort candidate books\n",
    "    ranked_items = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # build dataframe\n",
    "    recs = []\n",
    "    for item_idx, score in ranked_items:\n",
    "        isbn = idx_to_isbn[item_idx]\n",
    "        if isbn_to_num.get(isbn, 0) >= min_ratings:\n",
    "            recs.append((isbn, isbn_to_title.get(isbn, \"Unknown\"), score))\n",
    "        if len(recs) >= top_n:\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(recs, columns=[\"isbn\", \"title\", \"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "2b7c9acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0439064864</td>\n",
       "      <td>Harry Potter and the Chamber of Secrets (Book 2)</td>\n",
       "      <td>26.379893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0446310786</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>8.060360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>059035342X</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n",
       "      <td>5.851753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0316666343</td>\n",
       "      <td>The Lovely Bones: A Novel</td>\n",
       "      <td>5.795726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0312195516</td>\n",
       "      <td>The Red Tent (Bestselling Backlist)</td>\n",
       "      <td>5.020276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0142001740</td>\n",
       "      <td>The Secret Life of Bees</td>\n",
       "      <td>4.064008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0312278586</td>\n",
       "      <td>The Nanny Diaries: A Novel</td>\n",
       "      <td>3.381336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0446672211</td>\n",
       "      <td>Where the Heart Is (Oprah's Book Club (Paperba...</td>\n",
       "      <td>3.052909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0385504209</td>\n",
       "      <td>The Da Vinci Code</td>\n",
       "      <td>2.987927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0345370775</td>\n",
       "      <td>Jurassic Park</td>\n",
       "      <td>2.839533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         isbn                                              title      score\n",
       "0  0439064864   Harry Potter and the Chamber of Secrets (Book 2)  26.379893\n",
       "1  0446310786                              To Kill a Mockingbird   8.060360\n",
       "2  059035342X  Harry Potter and the Sorcerer's Stone (Harry P...   5.851753\n",
       "3  0316666343                          The Lovely Bones: A Novel   5.795726\n",
       "4  0312195516                The Red Tent (Bestselling Backlist)   5.020276\n",
       "5  0142001740                            The Secret Life of Bees   4.064008\n",
       "6  0312278586                         The Nanny Diaries: A Novel   3.381336\n",
       "7  0446672211  Where the Heart Is (Oprah's Book Club (Paperba...   3.052909\n",
       "8  0385504209                                  The Da Vinci Code   2.987927\n",
       "9  0345370775                                      Jurassic Park   2.839533"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recommended_books = recommend_books_userCF(\"6251\")\n",
    "display(recommended_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95991201",
   "metadata": {},
   "source": [
    "# Other Approach "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014696b9",
   "metadata": {},
   "source": [
    "### Overview\n",
    "The content-based recommender suggests books to a user based on the features of the books they have liked in the past.\n",
    "It builds a user profile by aggregating the features of previously liked books and recommends books that are most similar in content.\n",
    "\n",
    "### Steps\n",
    "\n",
    "#### 1. Feature Extraction\n",
    "- **Title:** TF-IDF vectorization (`min_df=2`, `max_df=0.7`)  \n",
    "- **Author & Publisher:** One-hot encoding  \n",
    "- **Year:** Min-Max scaling  \n",
    "\n",
    "#### 2. User Profile Construction\n",
    "- Select books the user rated above a threshold (e.g., 5).  \n",
    "- Compute the mean vector of the selected books’ features to represent the user profile.  \n",
    "\n",
    "#### 3. Recommendation\n",
    "- Compute cosine similarity between the user profile and all other books.  \n",
    "- Exclude books the user has already rated.  \n",
    "- Return the top-k most similar books.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "c531ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tfidfvectorizer to generate features for titles\n",
    "# min_df = 2 -> make a word features if it only accours at least twice\n",
    "# max_df = 0.7 -> if word appear in more than 70% of titles then ingore it\n",
    "tfidvec = TfidfVectorizer(min_df=2, max_df=0.7)\n",
    "vectorized_titles = tfidvec.fit_transform(books.title)\n",
    "\n",
    "# create datafram and put features for each book in it\n",
    "books_features = pd.DataFrame(\n",
    "    vectorized_titles.toarray(),\n",
    "    columns=tfidvec.get_feature_names_out(),\n",
    "    index=books[\"isbn\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "714d81f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20th</th>\n",
       "      <th>2nd</th>\n",
       "      <th>about</th>\n",
       "      <th>adventure</th>\n",
       "      <th>agency</th>\n",
       "      <th>air</th>\n",
       "      <th>alex</th>\n",
       "      <th>all</th>\n",
       "      <th>america</th>\n",
       "      <th>american</th>\n",
       "      <th>...</th>\n",
       "      <th>women</th>\n",
       "      <th>world</th>\n",
       "      <th>wrinkle</th>\n",
       "      <th>ya</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>your</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isbn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>002542730X</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0061009059</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0316776963</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0345413903</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0385424736</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            20th  2nd  about  adventure  agency  air  alex  all  america  \\\n",
       "isbn                                                                       \n",
       "002542730X   0.0  0.0    0.0        0.0     0.0  0.0   0.0  0.0      0.0   \n",
       "0061009059   0.0  0.0    0.0        0.0     0.0  0.0   0.0  0.0      0.0   \n",
       "0316776963   0.0  0.0    0.0        0.0     0.0  0.0   0.0  0.0      0.0   \n",
       "0345413903   0.0  0.0    0.0        0.0     0.0  0.0   0.0  0.0      0.0   \n",
       "0385424736   0.0  0.0    0.0        0.0     0.0  0.0   0.0  0.0      0.0   \n",
       "\n",
       "            american  ...  women  world  wrinkle   ya  year  years  you  \\\n",
       "isbn                  ...                                                 \n",
       "002542730X       0.0  ...    0.0    0.0      0.0  0.0   0.0    0.0  0.0   \n",
       "0061009059       0.0  ...    0.0    0.0      0.0  0.0   0.0    0.0  0.0   \n",
       "0316776963       0.0  ...    0.0    0.0      0.0  0.0   0.0    0.0  0.0   \n",
       "0345413903       0.0  ...    0.0    0.0      0.0  0.0   0.0    0.0  0.0   \n",
       "0385424736       0.0  ...    0.0    0.0      0.0  0.0   0.0    0.0  0.0   \n",
       "\n",
       "            young  your  zone  \n",
       "isbn                           \n",
       "002542730X    0.0   0.0   0.0  \n",
       "0061009059    0.0   0.0   0.0  \n",
       "0316776963    0.0   0.0   0.0  \n",
       "0345413903    0.0   0.0   0.0  \n",
       "0385424736    0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 402 columns]"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "03240536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode author using one hot encoding and add it as features\n",
    "encoder = OneHotEncoder()\n",
    "encoded_authors = encoder.fit_transform(books[[\"author\"]])\n",
    "encoded_authors = pd.DataFrame(\n",
    "    encoded_authors.toarray(),\n",
    "    columns=encoder.get_feature_names_out(),\n",
    "    index=books[\"isbn\"],\n",
    ")\n",
    "books_features = pd.concat((books_features, encoded_authors), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "9f0072c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode publisher using one hot encoding and add it as features\n",
    "encoder = OneHotEncoder()\n",
    "encoded_publisher = encoder.fit_transform(books[[\"publisher\"]])\n",
    "encoded_publisher = pd.DataFrame(\n",
    "    encoded_publisher.toarray(),\n",
    "    columns=encoder.get_feature_names_out(),\n",
    "    index=books[\"isbn\"],\n",
    ")\n",
    "books_features = pd.concat((books_features, encoded_publisher), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "1cd1b40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for year we use minmaxscaler as it is numerical column\n",
    "scaler = MinMaxScaler()\n",
    "scaled_numric = scaler.fit_transform(books[[\"year\"]])\n",
    "scaled_numric = pd.DataFrame(scaled_numric, columns=[\"year\"], index=books[\"isbn\"])\n",
    "books_features = pd.concat((books_features, scaled_numric), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "0e2bc81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20th</th>\n",
       "      <th>2nd</th>\n",
       "      <th>about</th>\n",
       "      <th>adventure</th>\n",
       "      <th>agency</th>\n",
       "      <th>air</th>\n",
       "      <th>alex</th>\n",
       "      <th>all</th>\n",
       "      <th>america</th>\n",
       "      <th>american</th>\n",
       "      <th>...</th>\n",
       "      <th>publisher_Warner Books</th>\n",
       "      <th>publisher_Warner Forever</th>\n",
       "      <th>publisher_Warner Vision</th>\n",
       "      <th>publisher_Washington Square Press</th>\n",
       "      <th>publisher_William Morrow &amp;amp; Company</th>\n",
       "      <th>publisher_Workman Pub Co</th>\n",
       "      <th>publisher_Workman Publishing</th>\n",
       "      <th>publisher_Yearling</th>\n",
       "      <th>publisher_Yearling Books</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isbn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>002542730X</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.787234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0061009059</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.808511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0316776963</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.936170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0345413903</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0385424736</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.808511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0451167538</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0671038443</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.914894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0060920084</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.463045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.702128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0553211404</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.553191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>042510107X</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.851064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>629 rows × 818 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            20th  2nd  about  adventure  agency  air  alex  all   america  \\\n",
       "isbn                                                                        \n",
       "002542730X   0.0  0.0    0.0        0.0     0.0  0.0   0.0  0.0  0.000000   \n",
       "0061009059   0.0  0.0    0.0        0.0     0.0  0.0   0.0  0.0  0.000000   \n",
       "0316776963   0.0  0.0    0.0        0.0     0.0  0.0   0.0  0.0  0.000000   \n",
       "0345413903   0.0  0.0    0.0        0.0     0.0  0.0   0.0  0.0  0.000000   \n",
       "0385424736   0.0  0.0    0.0        0.0     0.0  0.0   0.0  0.0  0.000000   \n",
       "...          ...  ...    ...        ...     ...  ...   ...  ...       ...   \n",
       "0451167538   0.0  0.0    0.0        0.0     0.0  0.0   0.0  0.0  0.000000   \n",
       "0671038443   0.0  0.0    0.0        0.0     0.0  0.0   0.0  0.0  0.000000   \n",
       "0060920084   0.0  0.0    0.0        0.0     0.0  0.0   0.0  0.0  0.463045   \n",
       "0553211404   0.0  0.0    0.0        0.0     0.0  0.0   0.0  0.0  0.000000   \n",
       "042510107X   0.0  0.0    0.0        0.0     0.0  0.0   0.0  0.0  0.000000   \n",
       "\n",
       "            american  ...  publisher_Warner Books  publisher_Warner Forever  \\\n",
       "isbn                  ...                                                     \n",
       "002542730X       0.0  ...                     0.0                       0.0   \n",
       "0061009059       0.0  ...                     0.0                       0.0   \n",
       "0316776963       0.0  ...                     0.0                       0.0   \n",
       "0345413903       0.0  ...                     0.0                       0.0   \n",
       "0385424736       0.0  ...                     0.0                       0.0   \n",
       "...              ...  ...                     ...                       ...   \n",
       "0451167538       0.0  ...                     0.0                       0.0   \n",
       "0671038443       0.0  ...                     0.0                       0.0   \n",
       "0060920084       0.0  ...                     0.0                       0.0   \n",
       "0553211404       0.0  ...                     0.0                       0.0   \n",
       "042510107X       0.0  ...                     0.0                       0.0   \n",
       "\n",
       "            publisher_Warner Vision  publisher_Washington Square Press  \\\n",
       "isbn                                                                     \n",
       "002542730X                      0.0                                0.0   \n",
       "0061009059                      0.0                                0.0   \n",
       "0316776963                      0.0                                0.0   \n",
       "0345413903                      0.0                                0.0   \n",
       "0385424736                      0.0                                0.0   \n",
       "...                             ...                                ...   \n",
       "0451167538                      0.0                                0.0   \n",
       "0671038443                      0.0                                0.0   \n",
       "0060920084                      0.0                                0.0   \n",
       "0553211404                      0.0                                0.0   \n",
       "042510107X                      0.0                                0.0   \n",
       "\n",
       "            publisher_William Morrow &amp; Company  publisher_Workman Pub Co  \\\n",
       "isbn                                                                           \n",
       "002542730X                                     0.0                       0.0   \n",
       "0061009059                                     0.0                       0.0   \n",
       "0316776963                                     0.0                       0.0   \n",
       "0345413903                                     0.0                       0.0   \n",
       "0385424736                                     0.0                       0.0   \n",
       "...                                            ...                       ...   \n",
       "0451167538                                     0.0                       0.0   \n",
       "0671038443                                     0.0                       0.0   \n",
       "0060920084                                     0.0                       0.0   \n",
       "0553211404                                     0.0                       0.0   \n",
       "042510107X                                     0.0                       0.0   \n",
       "\n",
       "            publisher_Workman Publishing  publisher_Yearling  \\\n",
       "isbn                                                           \n",
       "002542730X                           0.0                 0.0   \n",
       "0061009059                           0.0                 0.0   \n",
       "0316776963                           0.0                 0.0   \n",
       "0345413903                           0.0                 0.0   \n",
       "0385424736                           0.0                 0.0   \n",
       "...                                  ...                 ...   \n",
       "0451167538                           0.0                 0.0   \n",
       "0671038443                           0.0                 0.0   \n",
       "0060920084                           0.0                 0.0   \n",
       "0553211404                           0.0                 0.0   \n",
       "042510107X                           0.0                 0.0   \n",
       "\n",
       "            publisher_Yearling Books      year  \n",
       "isbn                                            \n",
       "002542730X                       0.0  0.787234  \n",
       "0061009059                       0.0  0.808511  \n",
       "0316776963                       0.0  0.936170  \n",
       "0345413903                       0.0  0.978723  \n",
       "0385424736                       0.0  0.808511  \n",
       "...                              ...       ...  \n",
       "0451167538                       0.0  1.000000  \n",
       "0671038443                       0.0  0.914894  \n",
       "0060920084                       0.0  0.702128  \n",
       "0553211404                       0.0  0.553191  \n",
       "042510107X                       0.0  0.851064  \n",
       "\n",
       "[629 rows x 818 columns]"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "b94df22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_books_content_based(book_isbn, num_books):\n",
    "    # compute cosine similarity between the given book and all other books\n",
    "    sim_scores = cosine_similarity(\n",
    "        books_features.loc[book_isbn].values.reshape(1, -1),\n",
    "        books_features.drop(book_isbn, axis=0),\n",
    "    )\n",
    "\n",
    "    # convert similarity scores into DataFrame with book ISBNs as index\n",
    "    sim_scores = pd.DataFrame(\n",
    "        sim_scores[0],\n",
    "        index=books_features.drop(book_isbn, axis=0).index,\n",
    "        columns=[\"score\"],\n",
    "    )\n",
    "\n",
    "    # return top N most similar books sorted by similarity score\n",
    "    return sim_scores.sort_values(\"score\", ascending=False).head(num_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "cc3024e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isbn</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0590353403</th>\n",
       "      <td>0.704027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>043935806X</th>\n",
       "      <td>0.667258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0439139600</th>\n",
       "      <td>0.620498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0439064872</th>\n",
       "      <td>0.619743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0439064864</th>\n",
       "      <td>0.617868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0439139597</th>\n",
       "      <td>0.616947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0439136369</th>\n",
       "      <td>0.616134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0439136350</th>\n",
       "      <td>0.612406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0425154092</th>\n",
       "      <td>0.304576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0345459202</th>\n",
       "      <td>0.269766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               score\n",
       "isbn                \n",
       "0590353403  0.704027\n",
       "043935806X  0.667258\n",
       "0439139600  0.620498\n",
       "0439064872  0.619743\n",
       "0439064864  0.617868\n",
       "0439139597  0.616947\n",
       "0439136369  0.616134\n",
       "0439136350  0.612406\n",
       "0425154092  0.304576\n",
       "0345459202  0.269766"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_books_content_based(\"059035342X\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "75310ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_for_user_content_based(user_id, num_books):\n",
    "    # keep only books the user rated above 5\n",
    "    user_pervious_books = train_df[\n",
    "        (train_df[\"user_id\"] == user_id) & (train_df[\"book_rating\"] > 5)\n",
    "    ]\n",
    "\n",
    "    # if user has no such books, return empty recommendations\n",
    "    if user_pervious_books.empty:\n",
    "        return pd.DataFrame([], columns=[\"score\"])\n",
    "\n",
    "    # take features for these books\n",
    "    user_pervious_books = books_features.loc[user_pervious_books[\"isbn\"]]\n",
    "\n",
    "    # build user profile\n",
    "    user_pervious_books_mean = user_pervious_books.mean().values.reshape(1, -1)\n",
    "\n",
    "    # compute similarity with all other books\n",
    "    sim_scores = cosine_similarity(\n",
    "        user_pervious_books_mean, books_features.drop(user_pervious_books.index, axis=0)\n",
    "    )\n",
    "\n",
    "    # wrap results\n",
    "    sim_scores = pd.DataFrame(\n",
    "        sim_scores[0],\n",
    "        index=books_features.drop(user_pervious_books.index, axis=0).index,\n",
    "        columns=[\"score\"],\n",
    "    )\n",
    "\n",
    "    return sim_scores.sort_values(\"score\", ascending=False).head(num_books).index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21e02c5",
   "metadata": {},
   "source": [
    "## User Based Colaporative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597dcbff",
   "metadata": {},
   "source": [
    "### Overview\n",
    "The collaborative filtering recommender suggests books to a user based on the ratings of similar users. It finds users with similar taste and recommends books they liked that the target user hasn’t read yet.\n",
    "\n",
    "### Steps\n",
    "\n",
    "#### 1. User-Book Matrix\n",
    "- Pivot the dataset to create a matrix with `user_id` as rows, `isbn` as columns, and `book_rating` as values.  \n",
    "- Fill missing ratings with the user’s mean rating.  \n",
    "\n",
    "#### 2. User Similarity\n",
    "- Compute cosine similarity between the target user and all other users.  \n",
    "\n",
    "#### 3. Top-N Recommendations\n",
    "- Identify top-k most similar users.  \n",
    "- Compute mean ratings of books from these users.  \n",
    "- Exclude books already rated by the target user.  \n",
    "- Return top-k books with the highest mean ratings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "a899d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pivot tabel user accros book\n",
    "user_book_pivot = train_df.pivot(index=\"user_id\", columns=\"isbn\", values=\"book_rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "8a304e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill null values with mean for each user\n",
    "user_book_pivot = user_book_pivot.apply(lambda row: row.fillna(row.mean()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "1f79b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_for_user_colaporative_filtering(user_id, num_books):\n",
    "    # Compute cosine similarity between the target user and all other users\n",
    "    sim = cosine_similarity(\n",
    "        user_book_pivot.loc[user_id].values.reshape(1, -1),\n",
    "        user_book_pivot.drop(user_id, axis=0).values,\n",
    "    )\n",
    "\n",
    "    # Store similarities in a DataFrame, indexed by user_id\n",
    "    users_score = pd.DataFrame(\n",
    "        sim.reshape(-1, 1),\n",
    "        columns=[\"score\"],\n",
    "        index=user_book_pivot.drop(user_id, axis=0).index,\n",
    "    )\n",
    "\n",
    "    # Pick top-5 most similar users\n",
    "    top_users = users_score.sort_values(\"score\", ascending=False).head(25).index\n",
    "\n",
    "    # Average their ratings for each book\n",
    "    mean_ratings = user_book_pivot.loc[top_users].mean(axis=0)\n",
    "\n",
    "    # Exclude user rated books\n",
    "    mean_ratings = mean_ratings[\n",
    "        ~mean_ratings.index.isin(train_df[train_df[\"user_id\"] == user_id][\"isbn\"])\n",
    "    ]\n",
    "\n",
    "    # Return top books with highest mean rating\n",
    "    return mean_ratings.sort_values(ascending=False).head(num_books).index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a42402",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623789a9",
   "metadata": {},
   "source": [
    "## Evaluation Metrics for Recommender Systems\n",
    "\n",
    "When evaluating recommendation models, we want to measure **how accurate** and **how well-ranked** the suggested items are.  \n",
    "We use three common metrics: **Precision@K, Recall@K, and NDCG@K**.\n",
    "\n",
    "\n",
    "\n",
    "### 1. Precision@K\n",
    "- **Definition:** Fraction of the top-𝐾 recommended items that are actually relevant (appear in the user’s test set).\n",
    "- **Formula:**\n",
    "  $$\n",
    "  \\text{Precision@K} = \\frac{\\text{ of relevant items in top-K}}{K}\n",
    "  $$\n",
    "- **Intuition:** \"Out of the top-𝐾 books I recommended, how many were correct?\"\n",
    "\n",
    "High precision means the system recommends fewer irrelevant items.\n",
    "\n",
    "\n",
    "\n",
    "### 2. Recall@K\n",
    "- **Definition:** Fraction of the user’s relevant items that were successfully recommended in the top-𝐾.\n",
    "- **Formula:**\n",
    "  $$\n",
    "  \\text{Recall@K} = \\frac{\\text{of relevant items in top-K}}{\\text{Total of relevant items}}\n",
    "  $$\n",
    "- **Intuition:** \"How many of the books the user actually liked did I manage to recommend?\"\n",
    "\n",
    "High recall means the system captures more of the user’s true interests.\n",
    "\n",
    "\n",
    "\n",
    "### 3. NDCG@K (Normalized Discounted Cumulative Gain)\n",
    "- **Definition:** Measures ranking quality by giving **higher weight to relevant items at the top** of the recommendation list.\n",
    "- **Formula:**\n",
    "  $$\n",
    "  DCG@K = \\sum_{i=1}^K \\frac{rel_i}{\\log_2(i+1)}\n",
    "  $$\n",
    "  $$\n",
    "  NDCG@K = \\frac{DCG@K}{IDCG@K}\n",
    "  $$\n",
    "  where:\n",
    "  - \\(rel_i = 1\\) if the item at rank *i* is relevant, else 0\n",
    "  - \\(IDCG@K\\) = best possible DCG if all relevant items were ranked perfectly at the top\n",
    "- **Intuition:** \"Did I rank the relevant books at the top of the list, where the user is most likely to notice them?\"\n",
    "\n",
    "✅ NDCG ranges from 0 to 1.  \n",
    "- 1 = perfect ranking (all relevant items at the top).  \n",
    "- 0 = no relevant items found.\n",
    "\n",
    "\n",
    "\n",
    "### 🔑 Summary\n",
    "- **Precision@K** → Accuracy of the recommendations.  \n",
    "- **Recall@K** → Coverage of relevant items.  \n",
    "- **NDCG@K** → Ranking quality (position matters).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "8104d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books_userCF_list(user_id, top_n=10, min_ratings=50):\n",
    "    recs = recommend_books_userCF(user_id, top_n, min_ratings)\n",
    "    if recs is None or recs.empty:\n",
    "        return []\n",
    "    return recs[\"isbn\"].tolist()\n",
    "\n",
    "\n",
    "def recommend_books_itemcf_list(user_id, top_n=10):\n",
    "    recs = recommend_books_itemcf_for_user(user_id, train_df, top_n=top_n)\n",
    "    if recs is None or recs.empty:\n",
    "        return []\n",
    "    return recs[\"isbn\"].tolist()\n",
    "\n",
    "\n",
    "def recommend_books_content_list(user_id, top_n=10):\n",
    "    recs = recommend_for_user_content_based(user_id, top_n)\n",
    "    if recs is None or len(recs) == 0:\n",
    "        return []\n",
    "    return list(recs)\n",
    "\n",
    "\n",
    "def recommend_for_user_colaborative_list(user_id, top_n=10):\n",
    "    try:\n",
    "        recs = recommend_for_user_colaporative_filtering(user_id, num_books=top_n)\n",
    "    except KeyError:\n",
    "        return []\n",
    "    return list(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "cb7a211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_list(recommender_fn, users, K=10):\n",
    "    precisions, recalls, ndcgs = [], [], []\n",
    "    for uid in users:\n",
    "        if uid not in gt:\n",
    "            continue\n",
    "        true_items = gt[uid]\n",
    "        pred_items = recommender_fn(uid, top_n=K)\n",
    "        if not pred_items:\n",
    "            continue\n",
    "\n",
    "        # hits\n",
    "        hits = [1 if item in true_items else 0 for item in pred_items]\n",
    "        n_hits = sum(hits)\n",
    "\n",
    "        # precision & recall\n",
    "        prec = n_hits / K\n",
    "        rec = n_hits / len(true_items) if len(true_items) > 0 else 0\n",
    "\n",
    "        # NDCG\n",
    "        dcg = sum([hits[i] / math.log2(i + 2) for i in range(len(hits))])\n",
    "        ideal_hits = min(len(true_items), K)\n",
    "        idcg = sum([1.0 / math.log2(i + 2) for i in range(ideal_hits)])\n",
    "        ndcg = dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "        ndcgs.append(ndcg)\n",
    "\n",
    "    return np.mean(precisions), np.mean(recalls), np.mean(ndcgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "f4ee0c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = test_df.groupby(\"user_id\")[\"isbn\"].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "2807197f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on 200 users...\n",
      "UserCF   → Precision@20: 0.006, Recall@20: 0.125, NDCG@20: 0.053\n",
      "Pivot-based UserCF → Precision@20: 0.003, Recall@20: 0.060, NDCG@20: 0.018\n",
      "ItemCF   → Precision@20: 0.007, Recall@20: 0.130, NDCG@20: 0.062\n",
      "Content  → Precision@20: 0.008, Recall@20: 0.161, NDCG@20: 0.071\n"
     ]
    }
   ],
   "source": [
    "sample_users = list(gt.keys())[:200]\n",
    "\n",
    "print(\"Evaluating on\", len(sample_users), \"users...\")\n",
    "\n",
    "p_u, r_u, n_u = evaluate_model_list(recommend_books_userCF_list, sample_users, K=20)\n",
    "p_cf, r_cf, n_cf = evaluate_model_list(\n",
    "    recommend_for_user_colaborative_list, sample_users, K=20\n",
    ")\n",
    "p_i, r_i, n_i = evaluate_model_list(recommend_books_itemcf_list, sample_users, K=20)\n",
    "p_c, r_c, n_c = evaluate_model_list(recommend_books_content_list, sample_users, K=20)\n",
    "\n",
    "print(f\"UserCF   → Precision@20: {p_u:.3f}, Recall@20: {r_u:.3f}, NDCG@20: {n_u:.3f}\")\n",
    "print(\n",
    "    f\"Pivot-based UserCF → Precision@20: {p_cf:.3f}, Recall@20: {r_cf:.3f}, NDCG@20: {n_cf:.3f}\"\n",
    ")\n",
    "print(f\"ItemCF   → Precision@20: {p_i:.3f}, Recall@20: {r_i:.3f}, NDCG@20: {n_i:.3f}\")\n",
    "print(f\"Content  → Precision@20: {p_c:.3f}, Recall@20: {r_c:.3f}, NDCG@20: {n_c:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acea062",
   "metadata": {},
   "source": [
    "# Summary of Implemented Recommendation Functions\n",
    "\n",
    "We built **four different recommender system functions**, each with a unique approach to generating book suggestions:\n",
    "\n",
    "---\n",
    "\n",
    "## 1. `recommend_books_userCF_list`\n",
    "- **Approach:** User-Based Collaborative Filtering (sparse matrix + cosine similarity).\n",
    "- **How it works:**\n",
    "  - Computes similarities between users based on their ratings.\n",
    "  - Finds top-k most similar users.\n",
    "  - Aggregates ratings of similar users to recommend new books.\n",
    "- **Strengths:**\n",
    "  - Personalized recommendations based on community behavior.\n",
    "  - Efficient due to sparse matrix operations.\n",
    "\n",
    "\n",
    "## 2. `recommend_for_user_colaborative_list`\n",
    "- **Approach:** User-Based Collaborative Filtering (pivot table + mean imputation).\n",
    "- **How it works:**\n",
    "  - Builds a full user–item matrix with missing values filled by each user’s mean rating.\n",
    "  - Computes cosine similarity between users.\n",
    "  - Uses ratings of top-k similar users to recommend books.\n",
    "- **Strengths:**\n",
    "  - Conceptually simple and easier to implement.\n",
    "  - Handles missing values via mean-filling.\n",
    "\n",
    "\n",
    "## 3. `recommend_books_itemcf_list`\n",
    "- **Approach:** Item-Based Collaborative Filtering.\n",
    "- **How it works:**\n",
    "  - Computes cosine similarity between items (books) based on user rating patterns.\n",
    "  - For a target user, finds books similar to the ones they rated highly.\n",
    "  - Aggregates similarity scores across multiple liked books.\n",
    "- **Strengths:**\n",
    "  - Effective when item similarities are strong.\n",
    "  - Recommendations are often interpretable (\"similar to book X\").\n",
    "\n",
    "\n",
    "## 4. `recommend_books_content_list`\n",
    "- **Approach:** Content-Based Filtering.\n",
    "- **How it works:**\n",
    "  - Extracts features from books (TF-IDF of title, one-hot encoding of author/publisher, scaled year).\n",
    "  - Builds a user profile from features of books they rated highly.\n",
    "  - Recommends books most similar in feature space.\n",
    "- **Strengths:**\n",
    "  - Can recommend new/unrated books (cold-start friendly for items).\n",
    "  - Personalized to user’s preferences based on book metadata.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
