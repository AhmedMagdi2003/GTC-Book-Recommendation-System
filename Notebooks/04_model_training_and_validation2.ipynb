{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca73add8",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "\n",
    "## 1. Data Loading & Preprocessing\n",
    "- Load `cleaned_book_ratings_plus.csv`.  \n",
    "- Convert `user_id` and `isbn` to string type.  \n",
    "- Separate books and users dataframes.  \n",
    "\n",
    "## 2. Train/Test Split\n",
    "- Split ratings so each user has ~30% of ratings in the test set.  \n",
    "- Function ensures each user appears in both train and test.  \n",
    "\n",
    "## 3. Non-Personalized Recommendation\n",
    "- Recommend top books based on `weighted_score`.  \n",
    "- Filter books with at least 30 ratings.  \n",
    "\n",
    "## 4. Content-Based Recommendation\n",
    "- TF-IDF vectorization of titles.  \n",
    "- One-hot encoding of authors and publishers.  \n",
    "- Min-max scaling for numerical features (year).  \n",
    "- Recommend based on cosine similarity with user profile.  \n",
    "\n",
    "## 5. Collaborative Filtering\n",
    "- Pivot table of users vs books.  \n",
    "- Fill missing values with user mean ratings.  \n",
    "- Recommend based on top-5 similar users using cosine similarity.  \n",
    "\n",
    "## 6. Evaluation\n",
    "- Precision@k and Recall@k computed for sampled users.  \n",
    "- Low precision/recall is expected due to sparsity of Book-Crossing dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e454ffb",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab7eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a72d6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/cleaned_book_ratings_plus.csv\")\n",
    "df['user_id']=df['user_id'].astype('str')\n",
    "df['isbn']=df['isbn'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70c33cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "books=df.drop_duplicates(subset='isbn')[['isbn','book_rating','title','author','year','publisher','img_url','num_of_rating','avg_book_rate','weighted_score']]\n",
    "users=df.drop_duplicates(subset='user_id')[['user_id','user_age','location','fav_author','fav_publisher']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d62eb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98605, 15)\n",
      "(10135, 10)\n",
      "(8203, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(books.shape)\n",
    "print(users.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ccd334",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4d1fb9",
   "metadata": {},
   "source": [
    "Split ratings into training set and test set so that:\n",
    "\n",
    "- Each user has at least num_of_rates_in_test ratings placed in the test set.\n",
    "\n",
    "- The rest of the ratings stay in the train set.\n",
    "\n",
    "This ensures every user appears in both train and test, which is crucial for evaluating recommendation systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d09bbb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check min number of rating for each user\n",
    "df.groupby('user_id').size().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "202b1607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_one_in_test(df):\n",
    "    grouped=df.groupby('user_id')\n",
    "    train_list=[]\n",
    "    test_list=[]\n",
    "    for uid,g in grouped:\n",
    "        #test size = 30%\n",
    "        #train size = 70%\n",
    "        num_of_rates_in_test=int(len(g)*0.3)\n",
    "        test_idx = g.sample(n=num_of_rates_in_test,random_state=42).index\n",
    "        train_idx = g.index.difference(test_idx)\n",
    "        test_list.extend(list(test_idx))\n",
    "        train_list.extend(list(train_idx))\n",
    "\n",
    "    train_df=df.loc[train_list]\n",
    "    test_df=df.loc[test_list]\n",
    "    return train_df.reset_index(drop=True), test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "179fd679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (73359, 15) test: (25246, 15)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df=train_test_split_one_in_test(df)\n",
    "print(\"train:\", train_df.shape, \"test:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d288c93d",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7ec58d",
   "metadata": {},
   "source": [
    "## Non-Personalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6d6a254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(929, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select only books which have sufficient number of ratings\n",
    "most_freq_books=books[books['num_of_rating']>30]\n",
    "most_freq_books.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b477ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0971880107', '0871138190', '039914739X'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function for non_personalized top books \n",
    "def select_non_personalized_top_books(num_books):\n",
    "    return most_freq_books.sort_values('weighted_score').head(num_books).isbn.values\n",
    "\n",
    "select_non_personalized_top_books(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b641de5",
   "metadata": {},
   "source": [
    "## Item Content Based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2205b70a",
   "metadata": {},
   "source": [
    "### Overview\n",
    "The content-based recommender suggests books to a user based on the features of the books they have liked in the past.\n",
    "It builds a user profile by aggregating the features of previously liked books and recommends books that are most similar in content.\n",
    "\n",
    "### Steps\n",
    "\n",
    "#### 1. Feature Extraction\n",
    "- **Title:** TF-IDF vectorization (`min_df=2`, `max_df=0.7`)  \n",
    "- **Author & Publisher:** One-hot encoding  \n",
    "- **Year:** Min-Max scaling  \n",
    "\n",
    "#### 2. User Profile Construction\n",
    "- Select books the user rated above a threshold (e.g., 5).  \n",
    "- Compute the mean vector of the selected books’ features to represent the user profile.  \n",
    "\n",
    "#### 3. Recommendation\n",
    "- Compute cosine similarity between the user profile and all other books.  \n",
    "- Exclude books the user has already rated.  \n",
    "- Return the top-k most similar books.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dec3106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tfidfvectorizer to generate features for titles\n",
    "#min_df = 2 -> make a word features if it only accours at least twice\n",
    "#max_df = 0.7 -> if word appear in more than 70% of titles then ingore it \n",
    "tfidvec=TfidfVectorizer(min_df=2,max_df=0.7)\n",
    "vectorized_titles=tfidvec.fit_transform(books.title)\n",
    "\n",
    "#create datafram and put features for each book in it\n",
    "books_features=pd.DataFrame(vectorized_titles.toarray(),columns=tfidvec.get_feature_names_out(),index=books['isbn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fce29f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode author using one hot encoding and add it as features\n",
    "encoder=OneHotEncoder()\n",
    "encoded_authors=encoder.fit_transform(books[['author']])\n",
    "encoded_authors=pd.DataFrame(encoded_authors.toarray(),columns=encoder.get_feature_names_out(),index=books['isbn'])\n",
    "books_features=pd.concat((books_features,encoded_authors),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab1201f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode publisher using one hot encoding and add it as features\n",
    "encoder=OneHotEncoder()\n",
    "encoded_publisher=encoder.fit_transform(books[['publisher']])\n",
    "encoded_publisher=pd.DataFrame(encoded_publisher.toarray(),columns=encoder.get_feature_names_out(),index=books['isbn'])\n",
    "books_features=pd.concat((books_features,encoded_publisher),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b732edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for year we use minmaxscaler as it is numerical column\n",
    "scaler=MinMaxScaler()\n",
    "scaled_numric=scaler.fit_transform(books[['year']])\n",
    "scaled_numric=pd.DataFrame(scaled_numric,columns=['year'],index=books['isbn'])\n",
    "books_features=pd.concat((books_features,scaled_numric),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42fcdb41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>03</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1001</th>\n",
       "      <th>101</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>publisher_Xlibris Corporation</th>\n",
       "      <th>publisher_Yearling</th>\n",
       "      <th>publisher_Yearling Books</th>\n",
       "      <th>publisher_Yossi Ghinsberg</th>\n",
       "      <th>publisher_Zebra Books</th>\n",
       "      <th>publisher_Zebra Books (Mass Market)</th>\n",
       "      <th>publisher_Zondervan Publishing Company</th>\n",
       "      <th>publisher_Zumaya Publications</th>\n",
       "      <th>publisher_btb</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isbn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0060517794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.976471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0671537458</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0679776818</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.905882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0060096195</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.964706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0141310340</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.964706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0886776791</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.894118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0553238132</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.929412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0804115419</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.964706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>075640049X</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.964706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0151010668</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10135 rows × 8709 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            000   03   10  100  1001  101   11   12   13   14  ...  \\\n",
       "isbn                                                           ...   \n",
       "0060517794  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "0671537458  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "0679776818  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "0060096195  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "0141310340  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "...         ...  ...  ...  ...   ...  ...  ...  ...  ...  ...  ...   \n",
       "0886776791  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "0553238132  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "0804115419  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "075640049X  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "0151010668  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "            publisher_Xlibris Corporation  publisher_Yearling  \\\n",
       "isbn                                                            \n",
       "0060517794                            0.0                 0.0   \n",
       "0671537458                            0.0                 0.0   \n",
       "0679776818                            0.0                 0.0   \n",
       "0060096195                            0.0                 0.0   \n",
       "0141310340                            0.0                 0.0   \n",
       "...                                   ...                 ...   \n",
       "0886776791                            0.0                 0.0   \n",
       "0553238132                            0.0                 0.0   \n",
       "0804115419                            0.0                 0.0   \n",
       "075640049X                            0.0                 0.0   \n",
       "0151010668                            0.0                 0.0   \n",
       "\n",
       "            publisher_Yearling Books  publisher_Yossi Ghinsberg  \\\n",
       "isbn                                                              \n",
       "0060517794                       0.0                        0.0   \n",
       "0671537458                       0.0                        0.0   \n",
       "0679776818                       0.0                        0.0   \n",
       "0060096195                       0.0                        0.0   \n",
       "0141310340                       0.0                        0.0   \n",
       "...                              ...                        ...   \n",
       "0886776791                       0.0                        0.0   \n",
       "0553238132                       0.0                        0.0   \n",
       "0804115419                       0.0                        0.0   \n",
       "075640049X                       0.0                        0.0   \n",
       "0151010668                       0.0                        0.0   \n",
       "\n",
       "            publisher_Zebra Books  publisher_Zebra Books (Mass Market)  \\\n",
       "isbn                                                                     \n",
       "0060517794                    0.0                                  0.0   \n",
       "0671537458                    0.0                                  0.0   \n",
       "0679776818                    0.0                                  0.0   \n",
       "0060096195                    0.0                                  0.0   \n",
       "0141310340                    0.0                                  0.0   \n",
       "...                           ...                                  ...   \n",
       "0886776791                    0.0                                  0.0   \n",
       "0553238132                    0.0                                  0.0   \n",
       "0804115419                    0.0                                  0.0   \n",
       "075640049X                    0.0                                  0.0   \n",
       "0151010668                    0.0                                  0.0   \n",
       "\n",
       "            publisher_Zondervan Publishing Company  \\\n",
       "isbn                                                 \n",
       "0060517794                                     0.0   \n",
       "0671537458                                     0.0   \n",
       "0679776818                                     0.0   \n",
       "0060096195                                     0.0   \n",
       "0141310340                                     0.0   \n",
       "...                                            ...   \n",
       "0886776791                                     0.0   \n",
       "0553238132                                     0.0   \n",
       "0804115419                                     0.0   \n",
       "075640049X                                     0.0   \n",
       "0151010668                                     0.0   \n",
       "\n",
       "            publisher_Zumaya Publications  publisher_btb      year  \n",
       "isbn                                                                \n",
       "0060517794                            0.0            0.0  0.976471  \n",
       "0671537458                            0.0            0.0  0.882353  \n",
       "0679776818                            0.0            0.0  0.905882  \n",
       "0060096195                            0.0            0.0  0.964706  \n",
       "0141310340                            0.0            0.0  0.964706  \n",
       "...                                   ...            ...       ...  \n",
       "0886776791                            0.0            0.0  0.894118  \n",
       "0553238132                            0.0            0.0  0.929412  \n",
       "0804115419                            0.0            0.0  0.964706  \n",
       "075640049X                            0.0            0.0  0.964706  \n",
       "0151010668                            0.0            0.0  0.988235  \n",
       "\n",
       "[10135 rows x 8709 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a12ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_books_content_based(book_isbn, num_books):\n",
    "    # compute cosine similarity between the given book and all other books\n",
    "    sim_scores = cosine_similarity(\n",
    "        books_features.loc[book_isbn].values.reshape(1, -1),\n",
    "        books_features.drop(book_isbn, axis=0)\n",
    "    )\n",
    "    \n",
    "    # convert similarity scores into DataFrame with book ISBNs as index\n",
    "    sim_scores = pd.DataFrame(\n",
    "        sim_scores[0],\n",
    "        index=books_features.drop(book_isbn, axis=0).index,\n",
    "        columns=['score']\n",
    "    )\n",
    "    \n",
    "    # return top N most similar books sorted by similarity score\n",
    "    return sim_scores.sort_values('score', ascending=False).head(num_books)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e6b8439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isbn</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0151009716</th>\n",
       "      <td>0.572806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0151006040</th>\n",
       "      <td>0.571068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0151006903</th>\n",
       "      <td>0.571068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               score\n",
       "isbn                \n",
       "0151009716  0.572806\n",
       "0151006040  0.571068\n",
       "0151006903  0.571068"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_books_content_based('0151010668',3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7577255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_for_user_content_based(user_id, num_books):\n",
    "    # keep only books the user rated above 5\n",
    "    user_pervious_books = df[(df['user_id'] == user_id) & (df['book_rating'] > 5)]\n",
    "\n",
    "    # if user has no such books, return empty recommendations\n",
    "    if user_pervious_books.empty:\n",
    "        return pd.DataFrame([], columns=['score'])\n",
    "\n",
    "    # take features for these books\n",
    "    user_pervious_books = books_features.loc[user_pervious_books['isbn']]\n",
    "\n",
    "    # build user profile\n",
    "    user_pervious_books_mean = user_pervious_books.mean().values.reshape(1, -1)\n",
    "\n",
    "    # compute similarity with all other books\n",
    "    sim_scores = cosine_similarity(\n",
    "        user_pervious_books_mean,\n",
    "        books_features.drop(user_pervious_books.index, axis=0)\n",
    "    )\n",
    "\n",
    "    # wrap results\n",
    "    sim_scores = pd.DataFrame(\n",
    "        sim_scores[0],\n",
    "        index=books_features.drop(user_pervious_books.index, axis=0).index,\n",
    "        columns=['score']\n",
    "    )\n",
    "\n",
    "    return sim_scores.sort_values('score', ascending=False).head(num_books).index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77b3bc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0671864173', '0060502258', '0060976845', '0671872001', '0670839809'], dtype='object', name='isbn')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_for_user_content_based('276747',5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed721a52",
   "metadata": {},
   "source": [
    "## User Based Colaporative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3ca378",
   "metadata": {},
   "source": [
    "### Overview\n",
    "The collaborative filtering recommender suggests books to a user based on the ratings of similar users. It finds users with similar taste and recommends books they liked that the target user hasn’t read yet.\n",
    "\n",
    "### Steps\n",
    "\n",
    "#### 1. User-Book Matrix\n",
    "- Pivot the dataset to create a matrix with `user_id` as rows, `isbn` as columns, and `book_rating` as values.  \n",
    "- Fill missing ratings with the user’s mean rating.  \n",
    "\n",
    "#### 2. User Similarity\n",
    "- Compute cosine similarity between the target user and all other users.  \n",
    "\n",
    "#### 3. Top-N Recommendations\n",
    "- Identify top-k most similar users.  \n",
    "- Compute mean ratings of books from these users.  \n",
    "- Exclude books already rated by the target user.  \n",
    "- Return top-k books with the highest mean ratings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88ea1b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pivot tabel user accros book\n",
    "user_book_pivot=train_df.pivot(index='user_id',columns='isbn',values='book_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fcaf745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill null values with mean for each user\n",
    "user_book_pivot=user_book_pivot.apply(lambda row:row.fillna(row.mean()),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9e1ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_for_user_colaporative_filtering(user_id, num_books):\n",
    "    # Compute cosine similarity between the target user and all other users\n",
    "    sim = cosine_similarity(\n",
    "        user_book_pivot.loc[user_id].values.reshape(1, -1),\n",
    "        user_book_pivot.drop(user_id, axis=0).values\n",
    "    )\n",
    "\n",
    "    # Store similarities in a DataFrame, indexed by user_id\n",
    "    users_score = pd.DataFrame(\n",
    "        sim.reshape(-1, 1),\n",
    "        columns=['score'],\n",
    "        index=user_book_pivot.drop(user_id, axis=0).index\n",
    "    )\n",
    "\n",
    "    # Pick top-5 most similar users\n",
    "    top_users = users_score.sort_values('score', ascending=False).head(5).index\n",
    "\n",
    "    # Average their ratings for each book\n",
    "    mean_ratings = user_book_pivot.loc[top_users].mean(axis=0)\n",
    "\n",
    "    # Exclude user rated books\n",
    "    mean_ratings= mean_ratings[~mean_ratings.index.isin(train_df[train_df['user_id']==user_id]['isbn'])]\n",
    "    \n",
    "    # Return top books with highest mean rating\n",
    "    return mean_ratings.sort_values(ascending=False).head(num_books).index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a508821d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0002251760', '0609806564', '0609801864', '0609803875', '0609804138'], dtype='object', name='isbn')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_for_user_colaporative_filtering('276747',5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7a9e52",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f9510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(model, test_df, k=5):\n",
    "    precisions, recalls = [], []\n",
    "    i=0\n",
    "    for user in test_df['user_id'].unique():\n",
    "        # true books the user rated in test\n",
    "        if i%50==0:\n",
    "            print(f'{model.__name__} :user number{i}')\n",
    "        i+=1\n",
    "        true_books = test_df[test_df['user_id']==user]['isbn'].values\n",
    "        \n",
    "        # skip users with no test data\n",
    "        if len(true_books) == 0:\n",
    "            continue\n",
    "\n",
    "        # get recommendations\n",
    "        try:\n",
    "            recs = model(user, k)  # your recommender function\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        recs = set(recs)  # recommended\n",
    "        true_books = set(true_books)  # actual\n",
    "        # compute precision and recall\n",
    "        hit = len(recs & true_books)\n",
    "        precisions.append(hit / k if k > 0 else 0)\n",
    "        recalls.append(hit / len(true_books) if len(true_books) > 0 else 0)\n",
    "\n",
    "    return np.mean(precisions), np.mean(recalls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f746e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_users=users.iloc[:500]['user_id']\n",
    "sample_users=test_df[test_df['user_id'].isin(sample_users)]\n",
    "sample_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddf80387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommend_for_user_content_based :user number0\n",
      "recommend_for_user_content_based :user number50\n",
      "recommend_for_user_content_based :user number100\n",
      "recommend_for_user_content_based :user number150\n",
      "recommend_for_user_content_based :user number200\n",
      "recommend_for_user_content_based :user number250\n",
      "recommend_for_user_content_based :user number300\n",
      "recommend_for_user_content_based :user number350\n",
      "recommend_for_user_colaporative_filtering :user number0\n",
      "recommend_for_user_colaporative_filtering :user number50\n",
      "recommend_for_user_colaporative_filtering :user number100\n",
      "recommend_for_user_colaporative_filtering :user number150\n",
      "recommend_for_user_colaporative_filtering :user number200\n",
      "recommend_for_user_colaporative_filtering :user number250\n",
      "recommend_for_user_colaporative_filtering :user number300\n",
      "recommend_for_user_colaporative_filtering :user number350\n",
      "Content-based: Precision@20 = 0.0010638297872340426 Recall@20 = 0.012879939209726445\n",
      "Collaborative: Precision@20 = 0.0007978723404255319 Recall@20 = 0.005516602192134107\n"
     ]
    }
   ],
   "source": [
    "p_cb, r_cb = precision_recall_at_k(recommend_for_user_content_based, sample_users, k=20)\n",
    "p_cf, r_cf = precision_recall_at_k(recommend_for_user_colaporative_filtering, sample_users, k=20)\n",
    "\n",
    "k=20\n",
    "print(f\"Content-based: Precision@{k} =\", p_cb, f\"Recall@{k} =\", r_cb)\n",
    "print(f\"Collaborative: Precision@{k} =\", p_cf, f\"Recall@{k} =\", r_cf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e503c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
